{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2023df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import noisereduce\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df = pd.read_csv('Summary_Emo_Eval.csv')\n",
    "\n",
    "lab_dic = {}\n",
    "for ind, row in lab_df.iterrows():\n",
    "    label = row['emotion']\n",
    "    if label == 'xxx':\n",
    "        lab_dic[row['wav_filename']] = 'oth' # other\n",
    "    elif label == 'exc': # excited\n",
    "        lab_dic[row['wav_filename']] = 'hap' # happy\n",
    "    else:\n",
    "        lab_dic[row['wav_filename']] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cbea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'IEMOCAP/'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for session in [1]:#range(1,6)\n",
    "    wav_sess_dir = dataset_dir + f'Session{session}/sentences/wav/'\n",
    "    dialog_names = os.listdir(wav_sess_dir)\n",
    "    for dialog in dialog_names:\n",
    "        if dialog.startswith('.'):\n",
    "            continue\n",
    "        wav_dialog_dir = wav_sess_dir+dialog+'/'\n",
    "        sentences_names = os.listdir(wav_dialog_dir)\n",
    "        for sentence in sentences_names:\n",
    "            if sentence.startswith('.'):\n",
    "                continue\n",
    "            if not sentence.endswith('wav'):\n",
    "                continue\n",
    "            label = [lab_dic[sentence[:-4]]]\n",
    "            if not label[0] in ['ang','hap','sad','neu']:\n",
    "                continue\n",
    "            wav_sentence_path = wav_dialog_dir+sentence\n",
    "            waveform, sr = librosa.load(wav_sentence_path, sr=None)\n",
    "            mfcc = np.mean(librosa.feature.mfcc(y=waveform, sr=sr, n_mfcc=40).T, axis=0)\n",
    "            melspec = librosa.feature.melspectrogram(y=waveform, sr=sr)\n",
    "            mel = np.mean(melspec.T, axis=0)\n",
    "            combined = np.hstack((mfcc, mel))\n",
    "            X.append(combined.tolist())\n",
    "            Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.array(X)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit([['ang'],['hap'],['sad'],['neu']])\n",
    "Y_all = enc.transform(Y).toarray()\n",
    "\n",
    "Xtrain, Xvaltest, Ytrain, Yvaltest = train_test_split(X_all, Y_all, test_size=0.2, random_state=42, shuffle=True)\n",
    "Xval, Xtest, Yval, Ytest = train_test_split(Xvaltest, Yvaltest, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "Xtrain_c = np.expand_dims(Xtrain, axis=1)\n",
    "Xval_c = np.expand_dims(Xval, axis=1)\n",
    "Xtest_c = np.expand_dims(Xtest, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 256, 5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(256, 128, 5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.conv4 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.conv5 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.conv6 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.fc = nn.Linear(2688, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "net = NNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f113326",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ts  = torch.Tensor(Xtrain_c)\n",
    "Ytrain_ts  = torch.Tensor(Ytrain)\n",
    "\n",
    "Xval_ts = torch.Tensor(Xval_c)\n",
    "Yval_ts = torch.Tensor(Yval)\n",
    "\n",
    "Xtest_ts = torch.Tensor(Xtest_c)\n",
    "Ytest_ts = torch.Tensor(Ytest)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(Xtrain_ts,Ytrain_ts)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "\n",
    "val_set = torch.utils.data.TensorDataset(Xval_ts,Yval_ts)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "\n",
    "test_set = torch.utils.data.TensorDataset(Xtest_ts,Ytest_ts)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.00001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    for batch, (inputs,targets) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.max(outputs, 1)[1]\n",
    "        classes = torch.max(targets, 1)[1]\n",
    "        train_correct = (preds == classes).sum()\n",
    "        train_acc += train_correct.item()\n",
    "        train_loss += loss.item()\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for inputs,targets in val_loader:\n",
    "                outputs = net(inputs)\n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                classes = torch.max(targets, 1)[1]\n",
    "                val_correct = (preds == classes).sum()\n",
    "                val_acc += val_correct.item()\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "            for inputs,targets in test_loader:\n",
    "                outputs = net(inputs)\n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                classes = torch.max(targets, 1)[1]\n",
    "                test_correct = (preds == classes).sum()\n",
    "                test_acc += test_correct.item()\n",
    "            net.train()\n",
    "        Train_loss = train_loss/(len(train_set))\n",
    "        Train_acc = 100*train_acc/(len(train_set))\n",
    "        Val_acc = 100*val_acc/(len(val_set))\n",
    "        Test_acc = 100*test_acc/(len(test_set))\n",
    "        print(f'Epoch {epoch:5d}:')\n",
    "        print(f'Training Loss {Train_loss:.3f}; Training Acc {Train_acc:.3f}%; Validation Acc {Val_acc:.3f}%; Test Acc {Test_acc:.3f}%')        \n",
    "print('Finished training')\n",
    "\n",
    "# after training, choose epoch based on validation accuracy\n",
    "# to do:\n",
    "# plot the loss/accuracy\n",
    "# get confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1051c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
