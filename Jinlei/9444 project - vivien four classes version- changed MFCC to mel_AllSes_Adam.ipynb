{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb2023df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import noisereduce\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import torchvision\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import rcParams#new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71cc4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df = pd.read_csv('Summary_Emo_Eval.csv')\n",
    "\n",
    "lab_dic = {}\n",
    "for ind, row in lab_df.iterrows():\n",
    "    label = row['emotion']\n",
    "    if label == 'xxx':\n",
    "        lab_dic[row['wav_filename']] = 'oth' # other\n",
    "    elif label == 'exc': # excited\n",
    "        lab_dic[row['wav_filename']] = 'hap' # happy\n",
    "    else:\n",
    "        lab_dic[row['wav_filename']] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53cbea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'IEMOCAP/'\n",
    "\n",
    "Y = []\n",
    "mel_list = []\n",
    "\n",
    "for session in [2]:#range(1,6)\n",
    "    wav_sess_dir = dataset_dir + f'Session{session}/sentences/wav/'\n",
    "    dialog_names = os.listdir(wav_sess_dir)\n",
    "    for dialog in dialog_names:\n",
    "        if dialog.startswith('.'):\n",
    "            continue\n",
    "        wav_dialog_dir = wav_sess_dir+dialog+'/'\n",
    "        sentences_names = os.listdir(wav_dialog_dir)\n",
    "        for sentence in sentences_names:\n",
    "            if sentence.startswith('.'):\n",
    "                continue\n",
    "            if not sentence.endswith('wav'):\n",
    "                continue\n",
    "            label = [lab_dic[sentence[:-4]]]\n",
    "            if not label[0] in ['ang','hap','sad','neu']:\n",
    "                continue\n",
    "            wav_sentence_path = wav_dialog_dir+sentence\n",
    "            waveform, sr = librosa.load(wav_sentence_path, sr=None)\n",
    "            melspec = librosa.feature.melspectrogram(y=waveform, sr=sr)\n",
    "            mel = np.mean(melspec.T, axis=0)\n",
    "            Y.append(label)\n",
    "            mel_list.append(mel.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d2e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mel_list\n",
    "\n",
    "X_all = np.array(X)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit([['ang'],['hap'],['sad'],['neu']])\n",
    "Y_all = enc.transform(Y).toarray()\n",
    "\n",
    "Xtrain, Xvaltest, Ytrain, Yvaltest = train_test_split(X_all, Y_all, test_size=0.2, random_state=42, shuffle=True)\n",
    "Xval, Xtest, Yval, Ytest = train_test_split(Xvaltest, Yvaltest, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "Xtrain_c = np.expand_dims(Xtrain, axis=1)\n",
    "Xval_c = np.expand_dims(Xval, axis=1)\n",
    "Xtest_c = np.expand_dims(Xtest, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bc9a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 256, 5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(256, 128, 5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.conv4 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.conv5 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.conv6 = nn.Conv1d(128, 128, 5, padding=2)\n",
    "        self.fc = nn.Linear(2048, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "net = NNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f113326",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ts  = torch.Tensor(Xtrain_c)\n",
    "Ytrain_ts  = torch.Tensor(Ytrain)\n",
    "\n",
    "Xval_ts = torch.Tensor(Xval_c)\n",
    "Yval_ts = torch.Tensor(Yval)\n",
    "\n",
    "Xtest_ts = torch.Tensor(Xtest_c)\n",
    "Ytest_ts = torch.Tensor(Ytest)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(Xtrain_ts,Ytrain_ts)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "\n",
    "val_set = torch.utils.data.TensorDataset(Xval_ts,Yval_ts)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "\n",
    "test_set = torch.utils.data.TensorDataset(Xtest_ts,Ytest_ts)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32495bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "def Tlabels(a):\n",
    "    L1=[]\n",
    "    for x in a:\n",
    "        L1.append(x)\n",
    "    return L1\n",
    "\n",
    "\n",
    "def Plabels(b):\n",
    "    L2=[]\n",
    "    for x in b:\n",
    "        L2.append(x)\n",
    "    return L2\n",
    "\n",
    "def conf_mat(cm,L1,L2):\n",
    "    if len(L2)<1:\n",
    "        return cm\n",
    "    for i in range(len(L1)):\n",
    "        if L2[i]==L1[i]:\n",
    "            cm[L1[i]][L1[i]]=cm[L1[i]][L1[i]]+1\n",
    "        else:\n",
    "            cm[L2[i]][L1[i]]=cm[L2[i]][L1[i]]+1\n",
    "    return cm\n",
    "            \n",
    "def cmplot(cm):\n",
    "    classes = ['ang','hap','sad','neu']\n",
    "    confusion_matrix = np.array(cm,dtype=np.int)\n",
    "    proportion=[]\n",
    "    for i in confusion_matrix:\n",
    "        for j in i:\n",
    "            temp=j/(np.sum(i))\n",
    "            proportion.append(temp)\n",
    "    pshow=[]\n",
    "    for i in proportion:\n",
    "        pt=\"%.2f%%\" % (i * 100)\n",
    "        pshow.append(pt)\n",
    "    proportion=np.array(proportion).reshape(4,4)  \n",
    "    pshow=np.array(pshow).reshape(4,4)\n",
    "    #print(pshow)\n",
    "    config = {\n",
    "        \"font.family\":'Times New Roman',  \n",
    "    }\n",
    "    rcParams.update(config)\n",
    "    plt.imshow(proportion, interpolation='nearest', cmap=plt.cm.Blues) \n",
    "    plt.title('confusion_matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes,fontsize=12)\n",
    "    plt.yticks(tick_marks, classes,fontsize=12)\n",
    "    \n",
    "    thresh = confusion_matrix.max() / 2.\n",
    "\n",
    "    iters = np.reshape([[[i,j] for j in range(4)] for i in range(4)],(confusion_matrix.size,2))\n",
    "    for i, j in iters:\n",
    "        if(i==j):\n",
    "            plt.text(j, i - 0.12, format(confusion_matrix[i, j]), va='center', ha='center', fontsize=12,color='white',weight=5) \n",
    "            plt.text(j, i + 0.12, pshow[i, j], va='center', ha='center', fontsize=12,color='white')\n",
    "        else:\n",
    "            plt.text(j, i-0.12, format(confusion_matrix[i, j]),va='center',ha='center',fontsize=12)\n",
    "            plt.text(j, i+0.12, pshow[i, j], va='center', ha='center', fontsize=12)\n",
    "    \n",
    "    plt.ylabel('True label',fontsize=16)\n",
    "    plt.xlabel('Predict label',fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4415d1fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'momentum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31164\\204871389.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'momentum'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    for batch, (inputs,targets) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.max(outputs, 1)[1]\n",
    "        classes = torch.max(targets, 1)[1]\n",
    "        train_correct = (preds == classes).sum()\n",
    "        train_acc += train_correct.item()\n",
    "        train_loss += loss.item()\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for inputs,targets in val_loader:\n",
    "                outputs = net(inputs)\n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                classes = torch.max(targets, 1)[1]\n",
    "                val_correct = (preds == classes).sum()\n",
    "                val_acc += val_correct.item()\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "            for inputs,targets in test_loader:\n",
    "                outputs = net(inputs)\n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                classes = torch.max(targets, 1)[1]\n",
    "                cm=conf_mat(cm,Tlabels(classes.numpy()),Plabels(preds.numpy())) #new\n",
    "                test_correct = (preds == classes).sum()\n",
    "                test_acc += test_correct.item()\n",
    "            net.train()\n",
    "        Train_loss = train_loss/(len(train_set))\n",
    "        Train_acc = 100*train_acc/(len(train_set))\n",
    "        Val_acc = 100*val_acc/(len(val_set))\n",
    "        Test_acc = 100*test_acc/(len(test_set))\n",
    "        print(f'Epoch {epoch:5d}:')\n",
    "        print(f'Training Loss {Train_loss:.3f}; Training Acc {Train_acc:.3f}%; Validation Acc {Val_acc:.3f}%; Test Acc {Test_acc:.3f}%') \n",
    "        cmplot(cm) #new       \n",
    "print('Finished training')\n",
    "\n",
    "# after training, choose epoch based on validation accuracy\n",
    "# to do:\n",
    "# plot the loss/accuracy\n",
    "# get confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1051c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
